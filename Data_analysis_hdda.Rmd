---
title: "Data exploration and regression assumptions analysis"
output: html_notebook
---
```{r}
library(ggplot2)
library(dplyr)
library(car)
library(e1071)
library(gtools)
library(lsmeans)
library(MASS)
library(het.test)
library(pander)
library(ggplot2)
library(lmtest)
```


```{r}
df <- read.csv("all_vars_df.csv")
```




------------------------------------------------------------------------------------------
Analisi e correzione della variabile y rispetto alla distribuzione normale (se necessaria)
------------------------------------------------------------------------------------------

```{r}
#Alcune statistiche:
summary(df$bmi)
#calcoliamoci l'asimmetria
s <- as.data.frame(df$bmi)
paste("L'indice di asimmetria e' pari a: ", apply(s, 2, skewness))
#Deviazione standard
paste("La deviazione standard e': ",sd(df$bmi))
#Differenza Interquantilica: 
paste("La differenza interquantilica e': ", IQR(df$bmi)) #distribuzione asimmetrica  e molti outliers


#Coefficiente di variazione:
paste("Il coefficiente di variazione e': ", (sd(df$bmi)/mean(df$bmi))*100)
```

```{r}
yplot <- function(x, nbreaks=10) {
               z <- x
hist(z, breaks=nbreaks, freq=FALSE,
     xlab="Price_charges",
     main="Distribuzione della variabile dipendente", col = "grey")
rug(jitter(z), col="brown")
curve(dnorm(x, mean=mean(z), sd=sd(z)),
      add=TRUE, col="red", lwd=2)
lines(density(z)$x, density(z)$y,
      col="black", lwd=2, lty = 2)
legend("topright",
       legend = c( "Normal Curve", "Kernel Density Curve"),
       lty=1:2, col=c("red","black"), cex=.7)
}
#Densità + Forma
yplot(df$bmi)
yplot(log(df$bmi))

#Analisi per sesso: 
ggplot(df, aes(x = bmi, fill = as.factor(sex1m2f))) + 
 geom_density(size = 0.6, alpha = .3, colour = "black") + 
 geom_rug(aes(x = bmi,y = 0), position = position_jitter(height = 0)) +
 labs(x = "Bmi", y =
"Densita'", fill = "Sesso") +
 ggtitle("Come si distribuisce bmi rispetto al sesso") 

```

```{r}
qqnorm(df$bmi, pch = 1, frame = FALSE, col = "tomato")
qqline(df$bmi, col = "steelblue", lwd = 2)
qqnorm(log(df$bmi), pch = 1, frame = FALSE, col = "tomato") #sembrerebbe che il log permetta di schiacciare la coda 
qqline(log(df$bmi), col = "steelblue", lwd = 2)
```

Presenta una forma leptocurtica con un asimmetria positiva

Test non parametrici: 

```{r}
shapiro.test(df$bmi) #H0: normalità, si rigetta l'ipotesi nulla 
shapiro.test(log(df$bmi)) #Il valore W si avvicina di più a 1 
```

```{r}
plot(df$bmi)
abline(h=36, col="blue")
abline(h=10, col = "blue")
text(df$bmi, labels=df$id, cex= 0.7)
```

```{r}
no_out <- df
id_out <- c(4018,4009,3056,3046,3022,3018)
#no_out <- df[-c(15,52,83,88,48),]
no_out <- no_out[!(no_out$id %in% id_out),]
```

```{r}
qqnorm(no_out$bmi, pch = 1, frame = FALSE, col = "tomato")
qqline(no_out$bmi, col = "steelblue", lwd = 2)
qqnorm(log(no_out$bmi), pch = 1, frame = FALSE, col = "tomato") 
qqline(log(no_out$bmi), col = "steelblue", lwd = 2)
```

```{r}
shapiro.test(no_out$bmi) #H0: normalità, si accetta l'ipotesi di normalità dopo aver eliminato 7 outliers ()
shapiro.test(log(no_out$bmi)) #In questo caso il log peggiora 
```

--------------------------------------------
Continuo analisi esplorativa delle variabili
--------------------------------------------

#Testiamo se esiste una differenza significativa nelle due popolazioni maschili e femminili:
```{r}
wilcox.test(df$bmi~df$sex1m2f,  conf.int = T, paired = F) #non esiste una differenza significativa tra le distribuzioni delle due popolazioni legate al sesso. Si accetta l'ipotesi nulla ad un livello di confidenza del 95%. 
```

```{r}
#Analisi per età:
df$age <- as.integer(df$age)
df$age_discr <- quantcut(df$age,3) #quantile discretization in 3 bins
ggplot(df, aes(x = bmi, fill = age_discr)) + 
 geom_density(size = 0.6, alpha = .3, colour = "black") + 
 geom_rug(aes(x = bmi,y = 0), position = position_jitter(height = 0)) +
 labs(x = "Bmi", y =
"Densita'", fill = "Eta' discretizzata") +
 ggtitle("Come si distribuisce il bmi rispetto all'eta'") 
```
Chi-squared test tra fasce di età e bmi:
```{r}
df$bmi_discr <- quantcut(df$bmi,3)
age_bmi <- table(df$bmi_discr, df$age_discr)
chisq.test(age_bmi)
#Dal test del chi-quadro emerge che esiste una dipendenza tra le varie fasce di età e il bmi
```

```{r}
options(scipen=999)
df$bdate <- NULL
df$zbmius <- NULL
df$zbmicatus <- NULL
df$bmicat1norm2ow3ob <- NULL
#Analisi pca nutrienti, var. demografiche, bmi
var_num <- c("bmi", "PC1_nut","PC2_nut","PC3_nut","PC4_nut","PC5_nut","age","sex1m2f")
cor(df[,var_num])
plot(no_out[,var_num],cex=.8, col = "tomato")


var_num <- c("bmi", "PC1_taxa","PC2_taxa","PC3_taxa","PC4_taxa","PC5_taxa","PC6_taxa","age","sex1m2f", "PC1_nut","PC2_nut","PC3_nut","PC4_nut","PC5_nut", "weightkg","heightcm")
library(corrplot)

coor <- cor(no_out[,var_num])
corrplot(coor, method="color", addCoef.col="black", order = "AOE")
```

------------
Modellazione
------------

```{r}
mod_lin <- lm(bmi ~  PC1_taxa + PC2_taxa + PC3_taxa + PC4_taxa + PC5_taxa + PC6_taxa + age + sex1m2f, no_out) 
summary(mod_lin)
anova(mod_lin)
```

# Test per omoschedasticità:
```{r}
white.test <- function(lmod,data=no_out){
  u2 <- lmod$residuals^2
  y <- fitted(lmod)
  Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
  LM <- nrow(data)*Ru2
  p.value <- 1-pchisq(LM, 2)
  data.frame("Test statistic"=LM,"P value"=p.value)
}
white.test(mod_lin)
```
#Si accetta l'assunzione di omoschedasticità


-------------------------
VERIFICO AUTOCORRELAZIONE
-------------------------
1)Distribuzione dei residui
```{r}
plot(1:nrow(no_out),resid(mod_lin),xlab="Observation Index",ylab="Residui",pch=19) #Graficamente non si vede bene la correlazine dei residui. E' piu utile in questo caso il test di dwatson
abline(h=0,col=2,lwd=3,lty=2)
```

Test di darbin-watson
```{r}
library(pander)
pander(dwtest(mod_lin),big.mark=",") #essendo la statistica d compresa tra 1 e 3 possiamo affermare che non c'? autocorrelazione seriale di primo ordine tra i residui (ricorda che per d<1 c'? autocorrelazione positiva mentre per d>3 c'? autocorrelazione negativa) In ogni caso non mi aspetto un'autocorrelazione dei residui in quanto non ? una serie temporale (e anche se ci fosse autocorrelazione potrei decidere di non correggerla proprio perch? non ? una serie temporale)
```

---------------------
Normalità dei residui
---------------------

Test della Kurtosis 
```{r}
library(normtest)
kurtosis.norm.test(mod_lin$residuals, nrepl=2000)  #H0 normalit??, p-value < livello alpha: non norm.
#In questo caso si rifiuta l'ipotesi di normalit?? 
```
 Test di shapiro wilk
```{r}
shapiro.test(mod_lin$residuals) #Ipotesi di normalit? rifiutata
```

```{r}
stdres <- rstandard(mod_lin) #residui standardizzati
probDist <- pnorm(stdres) #probabilit?? dei residui standardizzati
plot(ppoints(length(stdres)), sort(probDist), main = "PP-Plot", xlab = "Observed Probability", ylab = "Expected Probability")
abline(0,1)
```

Outliers sui residui
```{r}
library(olsrr)
olsrr::ols_plot_cooksd_chart(mod_lin)
```

```{r}
# Stepwise regression: 
library(tidyverse)
library(caret)
library(leaps)
library(MASS)

new_df <- read.csv("datasets/genera_all_vars_df.csv")
id_out <- c(4018,4009,3056,3046,3022,3018)
new_df$age <- as.integer(new_df$age)
#new_df <- new_df

new_df <- new_df[!(new_df$id %in% id_out),]
lista <- c("id","visitdate","heightcm","vdate","heightm","zbmius","zbmicatus","birthdate","bdate","bmicat1norm2ow3ob","weightkg",
           "PC1_taxa","PC2_taxa")

new_df[,lista] <- list(NULL)
new_df <- new_df[,-c(4:108)]


#Train e test split:
# Random sample indexes
set.seed(20)
train_index <- sample(1:nrow(new_df), 0.9 * nrow(new_df))
test_index <- setdiff(1:nrow(new_df), train_index)

# Build X_train, y_train, X_test, y_test
X_train <- new_df[train_index, -3]
y_train <- new_df[train_index, "bmi"]

X_test <- new_df[test_index, -3]
y_test <- new_df[test_index, "bmi"]

train_data <- cbind(y_train,X_train)
# Fit the full model 
full.model <- lm(y_train  ~. , data = X_train)

#full.model <- lm(bmi ~ PC1_nut+PC2_nut + PC3_nut + PC4_nut + PC5_nut + age + sex1m2f +
 #                  PC1_taxa+PC2_taxa, data = new_df) 

summary(full.model)
# Stepwise regression model
step.modelb <- stepAIC(full.model, direction = "backward", 
                      trace = FALSE)
step.modelf <- stepAIC(full.model, direction = "forward", 
                      trace = FALSE)
step.modelb
step.modelf
summary(step.modelb)
summary(step.modelf)

#Oppure: 
# Train the model
train.control <- trainControl(method = "cv", repeats = 1, number = 9,savePred=T) #procedura di crossvalidation, number = 9, repeats = 1
step.modelB <- train(y_train ~., data = train_data,
                    method = "leapForward", 
                    tuneGrid = data.frame(nvmax = 1:44), #da 1 a 3 variabili
                    trControl = train.control
                    )
trellis.par.set(caretTheme())
ggplot(step.modelB, metric = "MAE")  
ggplot(step.modelB, metric = "Rsquared")
ggplot(step.modelB, metric = "RMSE") 
step.modelB$finalModel
step.modelB$results

coef(step.modelB$finalModel, as.double(step.modelB$bestTune))
step.modelB$bestTune
summary(step.modelB$finalModel)
step.modelB$results

#Di nuovo stepwise regression nel subset scelto: 
train.control <- trainControl(method = "cv", repeats = 1, number = 9,savePred=T) #procedura di crossvalidation, number = 9, repeats = 1
step.modelB <- train(y_train ~., data = train_data,
                    method = "leapForward", 
                    tuneGrid = data.frame(nvmax = 1:44), #da 1 a 3 variabili
                    trControl = train.control
                    )

#CV con i regressori scelti: 
train.control <- trainControl(method = "cv", repeats = 1, number = 9,savePred=T) #procedura di crossvalidation, number = 9, repeats = 1
step.modelB <- train(y_train ~ sex1m2f + age + k__Bacteria.p__Bacteroidetes.c__Bacteroidia.o__Bacteroidales.f__Porphyromonadaceae.g__Parabacteroides + 
    k__Bacteria.p__Bacteroidetes.c__Bacteroidia.o__Bacteroidales.f__Prevotellaceae.g__Prevotella + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Clostridiaceae.g__SMB53 + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Lachnospiraceae.g__Blautia + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Lachnospiraceae.g__Clostridium + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Lachnospiraceae.g__Lachnobacterium + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Veillonellaceae.g__Megasphaera + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Veillonellaceae.g__Phascolarctobacterium, 
    data = train_data, method = "leapBackward", 
                    tuneGrid = data.frame(nvmax = 1:10), #da 1 a 3 variabili
                    trControl = train.control,
                    )


predict(step.modelB$finalModel, interval = "confidence")
step.modelB
#Un altro approccio di stepwise regression:
library(leaps)
leaps <-regsubsets(y_train ~ sex1m2f + age + k__Bacteria.p__Bacteroidetes.c__Bacteroidia.o__Bacteroidales.f__Porphyromonadaceae.g__Parabacteroides +
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Clostridiaceae.g__SMB53 + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Lachnospiraceae.g__Blautia + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Lachnospiraceae.g__Lachnobacterium + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Veillonellaceae.g__Megasphaera + 
    #k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Veillonellaceae.g__Phascolarctobacterium + 
    PC5_nut, X_train,method = "forward") #guarda solo R^2 ma non la significatività dei parametri.
plot(leaps, scale="adjr2") 


train.control <- trainControl(method = "cv", repeats = 1, number = 10,savePred=T)
model <- train(y_train ~ sex1m2f + age + k__Bacteria.p__Bacteroidetes.c__Bacteroidia.o__Bacteroidales.f__Porphyromonadaceae.g__Parabacteroides +
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Clostridiaceae.g__SMB53 + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Lachnospiraceae.g__Blautia + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Lachnospiraceae.g__Lachnobacterium + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Veillonellaceae.g__Megasphaera + 
    PC5_nut, train_data, method = "lm", trControl = train.control)

model$resample
final_model <-lm(y_train ~ sex1m2f + age + k__Bacteria.p__Bacteroidetes.c__Bacteroidia.o__Bacteroidales.f__Porphyromonadaceae.g__Parabacteroides +
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Clostridiaceae.g__SMB53 + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Lachnospiraceae.g__Blautia + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Lachnospiraceae.g__Lachnobacterium + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Veillonellaceae.g__Megasphaera + 
    PC5_nut, X_train) #mape 0.07

final_model2 <- lm(y_train ~ sex1m2f + age + k__Bacteria.p__Bacteroidetes.c__Bacteroidia.o__Bacteroidales.f__Porphyromonadaceae.g__Parabacteroides + 
    k__Bacteria.p__Bacteroidetes.c__Bacteroidia.o__Bacteroidales.f__Prevotellaceae.g__Prevotella + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Clostridiaceae.g__SMB53 + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Lachnospiraceae.g__Blautia + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Lachnospiraceae.g__Clostridium + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Lachnospiraceae.g__Lachnobacterium + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Veillonellaceae.g__Megasphaera + 
    k__Bacteria.p__Firmicutes.c__Clostridia.o__Clostridiales.f__Veillonellaceae.g__Phascolarctobacterium, 
    data = train_data) #mape 0.08

summary(final_model2)
summary(final_model)
shapiro.test(final_model$residuals) 
white.test(final_model)

qqnorm(final_model$residuals, pch = 1, frame = FALSE, col = "tomato")
qqline(final_model$residuals, col = "steelblue", lwd = 2)

ols_vif_tol(final_model) #VIF minore di 10 non sussiste collinearità delle variabili

#Predizioni:
predictions <- predict(final_model, X_test)
Metrics::mae(y_test,predictions$predictions)

predictions <- as.data.frame(predictions)
predictions$true_y <- y_test
predictions
ggiraphExtra::ggPredict(final_model)

#Plot hyperplane
rockchalk::plotPlane(final_model, plotx1 = "sex1m2f", plotx2 = "age",ticktype = "detailed",npp = 10, theta = 30)
```


